---
sidebar: sidebar
permalink: hu_ol_76.html
keywords: host utilities, oracle, linux, 7.6, netapp, ontap
summary: Describes how to use Oracle Linux 7.6 with ONTAP
---

= Using Oracle Linux 7.6 with NetApp ONTAP
:toc: macro
:hardbreaks:
:toclevels: 1
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./media/

== Installing the Linux Unified Host Utilities

include::_include/hu/reuse_hu_installing_luhu_with32.adoc[]

== SAN Toolkit

include::_include/hu/reuse_hu_san_toolkit.adoc[]

== SAN Booting

.Before you begin
If you decide to use SAN booting, it must be supported by your configuration. You can use the link:https://mysupport.netapp.com/matrix/imt.jsp?components=86309;&solution=1&isHWU&src=IMT[NetApp Interoperability Matrix Tool^] to verify that your OS, HBA, HBA firmware and the HBA boot BIOS, and ONTAP version are supported.

include::_include/hu/reuse_hu_san_booting_steps.adoc[]

== Multipathing

For Oracle Linux 7.6 the /etc/multipath.conf file must exist, but you do not need to make specific changes to the file. Oracle Linux 7.6 is compiled with all settings required to recognize and correctly manage ONTAP LUNs.

include::_include/hu/reuse_hu_multipathing_non_asa.adoc[]
include::_include/hu/reuse_hu_non_asa_configuration_solo.adoc[]

----
# multipath -ll
3600a09803831347657244e527766394e dm-5 NETAPP,LUN C-Mode
size=80G features='4 queue_if_no_path pg_init_retries 50 retain_attached_hw_handle' hwhandler='1 alua' wp=rw
|-+- policy='service-time 0' prio=50 status=active
| |- 11:0:1:0 sdj 8:144 active ready running
| |- 11:0:2:0 sdr 65:16 active ready running
`-+- policy='service-time 0' prio=10 status=enabled
|- 11:0:0:0 sdb 8:i6 active ready running
|- 12:0:0:0 sdz 65:144 active ready running
----

include::_include/hu/reuse_hu_asa_configuration_note.adoc[]

== Recommended Settings

The Oracle Linux 7.6 OS is compiled to recognize ONTAP LUNs and automatically set all configuration parameters correctly.
include::_include/hu/reuse_hu_recommended_settings.adoc[]


[cols=2*,options="header"]
|===
| Parameter
| Setting
| detect_prio | yes
| dev_loss_tmo | "infinity"
| failback | immediate
| fast_io_fail_tmo | 5
| features | "3 queue_if_no_path pg_init_retries 50"
| flush_on_last_del | "yes"
| hardware_handler | "0"
| path_checker | "tur"
| path_grouping_policy | "group_by_prio"
| path_selector | "service-time 0"
| polling_interval | 5
| prio | "ontap"
| product | LUN.*
| retain_attached_hw_handler | yes
| rr_weight | "uniform"
| user_friendly_names | no
| vendor | NETAPP
|===

.Example

The following example shows how to correct an overridden default. In this case, the `multipath.conf` file defines values for `path_checker` and `detect_prio` that are not compatible with ONTAP LUNs. If they cannot be removed because of other SAN arrays still attached to the host, these parameters can be corrected specifically for ONTAP LUNs with a device stanza.

----
defaults {
 path_checker readsector0
 detect_prio no
 }
devices {
 device {
 vendor "NETAPP "
 product "LUN.*"
 path_checker tur
 detect_prio yes
 }
}
----

== Known Problems and Limitations

[cols=4*,options="header"]
|===
| NetApp Bug ID
| Title
| Description
| Bugzilla ID
| link:https://mysupport.netapp.com/NOW/cgi-bin/bol?Type=Detail&Display=1202736[1202736] | LUNs might not be available during host discovery due to "Not Present" state of remote ports on a OL7U6 host with QLogic QLE2742 adapter |During host discovery, the status of Fibre Channel (FC) remote ports on a OL7U6 host with a QLogic QLE2742 adapter might enter into "Not Present" state. Remote ports with a "Not Present" state might cause paths to LUNs to become unavailable. During storage failover, the path redundancy might be reduced and result in an I/O outage.
You can check the remote port status by entering the following command:
# cat /sys/class/fc_remote_ports/rport-*/port_state
The following is an example of the output that is displayed:
  Online
  Online
  Not Present
  Online
  Online | link:https://bugzilla.oracle.com/bugzilla/show_bug.cgi?id=16613[16613^]
| link:https://mysupport.netapp.com/NOW/cgi-bin/bol?Type=Detail&Display=1204078[1204078^] | Kernel disruption occurs on Oracle Linux 7.6 running with Qlogic(QLE2672) 16GB FC HBA during storage failover operations | During storage failover operations on the Oracle Linux 7.6 with a Qlogic QLE2672 Fibre Channel (FC) host bus adapter (HBA), a kernel disruption occurs due to a panic in the kernel. The kernel panic causes Oracle Linux 7.6 to reboot, which leads to an application disruption.   If the kdump mechanism is enabled, the kernel panic generates a vmcore file located in the /var/crash/ directory. You can analyze the vmcore file to determine the cause of the panic.  After the kernel disruption, you can reboot the host OS and recover the operating system, and then you can restart any applications as required. | link:https://bugzilla.oracle.com/bugzilla/show_bug.cgi?id=16606[16606]
| link:https://mysupport.netapp.com/NOW/cgi-bin/bol?Type=Detail&Display=1204351[1204351^] | Kernel disruption might occur on Oracle Linux 7.6 running with Qlogic(QLE2742) 32GB FC HBA during storage failover operations | During storage failover operations on the Oracle Linux 7.6 with a Qlogic QLE2742 Fibre Channel (FC) host bus adapter (HBA), a kernel disruption might occur due to a panic in the kernel. The kernel panic causes Oracle Linux 7.6 to reboot, which leads to an application disruption. If the kdump mechanism is enabled, the kernel panic generates a vmcore file located in the /var/crash/ directory. You can analyze the vmcore file to determine the cause of the panic.
After the kernel disruption, you can reboot the host OS and recover the operating system, and then you can restart any applications as required. | link:https://bugzilla.oracle.com/bugzilla/show_bug.cgi?id=16605[16605]
| link:https://mysupport.netapp.com/NOW/cgi-bin/bol?Type=Detail&Display=1204352[1204352^] | Kernel disruption might occur on Oracle Linux 7.6 running with Emulex (LPe32002-M2)32GB FC HBA during storage failover operations | During storage failover operations on the Oracle Linux 7.6 with an Emulex LPe32002-M2 Fibre Channel (FC) host bus adapter (HBA), a kernel disruption might occur due to a panic in the kernel. The kernel panic causes Oracle Linux 7.6 to reboot, which leads to an application disruption.
 If the kdump mechanism is enabled, the kernel panic generates a vmcore file located in the /var/crash/ directory. You can analyze the vmcore file to determine the cause of the panic.
After the kernel disruption, you can reboot the host OS and recover the operating system, and then you can restart any applications as required. | link:https://bugzilla.oracle.com/bugzilla/show_bug.cgi?id=16607[16607]
| link:https://mysupport.netapp.com/NOW/cgi-bin/bol?Type=Detail&Display=1246134[11246134^] | No I/O progress on Oracle Linux 7.6 with UEK5U2 kernel, running with an Emulex LPe16002B-M6 16G FC HBA during storage failover operations | During storage failover operations on the Oracle Linux 7.6 with the UEK5U2 kernel running with an Emulex LPe16002B-M6 16G Fibre Channel (FC) host bus adapter (HBA), I/O progress might stop due to reports getting blocked. The storage failover operation reports change from an "online" state to a "blocked" state, causing a delay in read and write operations. After the operation has completed successfully, the reports fail to move back to an "online" state and continue to remain in a "blocked" state. | link:https://bugzilla.oracle.com/bugzilla/show_bug.cgi?id=16852[16852]
| link:https://mysupport.netapp.com/NOW/cgi-bin/bol?Type=Detail&Display=1246327[1246327^] | Remote port status on QLogic QLE2672 16G host blocked during storage failover operations | Fibre Channel (FC) remote ports might be blocked on Red Hat Enterprise Linux (RHEL) 7.6 with the QLogic QLE2672 16G host during storage failover operations. Because the logical interfaces go down when a storage node is down, the remote ports set the storage node status to blocked. IO progress might stop due to the blocked ports if you are running both a QLogic QLE2672 16G host and a QLE2742 32GB Fibre Channel (FC) host bus adapter (HBA).
When the storage node returns to its optimal state, the logical interfaces also come up and the remote ports should be online. However, the remote ports might still be blocked. This blocked state registers as failed faulty to LUNS at the multipath layer. You can verify the state of the remote ports with the following command:
 # cat /sys/class/fc_remote_ports/rport-*/port_stat
 You should see the following output:
 Blocked
 Blocked
 Blocked
 Blocked
 Online
 Online | link:https://bugzilla.oracle.com/bugzilla/show_bug.cgi?id=16853[16853^]
|===
include::_include/hu/reuse_hu_ol_issues_note.adoc[]

== Release Notes

include::_include/hu/reuse_hu_release_notes.adoc[]
